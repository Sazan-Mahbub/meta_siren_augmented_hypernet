{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTwikOyWZobA"
   },
   "source": [
    "# MetaSDF & Meta-SIREN\n",
    "\n",
    "This is a colab to explore MetaSDF, and its applications to rapidly fit neural implicit representations.\n",
    "\n",
    "Make sure to switch the runtime type to \"GPU\" under \"Runtime --> Change Runtime Type\"!\n",
    "\n",
    "We will show you how to run two experiments using gradient-based meta-learning: \n",
    "* [Fitting an image in 3 gradient descent steps with SIREN](#section_1)\n",
    "* [Fitting 2D Signed Distance Functions of MNIST digits](#section_2)\n",
    "\n",
    "Let's go! \n",
    "\n",
    "First, the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJ49alfvZobQ",
    "outputId": "627391a5-abd0-4101-8a73-66302c056cbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sazan\\AppData\\Local\\Temp/ipykernel_13076/3975817298.py:12: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import OrderedDict, Mapping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import scipy.ndimage\n",
    "from torch import nn \n",
    "from collections import OrderedDict, Mapping \n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "\n",
    "from torch.nn.init import _calculate_correct_fan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrsG6X9cDsZe",
    "outputId": "a6e98051-c4ed-4948-8475-5c9775f19c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 15]) torch.Size([2, 3]) \n",
      ">>\n",
      " tensor([[ 1,  2,  3,  1,  2,  3,  1,  2,  3,  1,  2,  3,  1,  2,  3],\n",
      "        [10, 20, 30, 10, 20, 30, 10, 20, 30, 10, 20, 30, 10, 20, 30]]) \n",
      " tensor([[[ 1,  2,  3],\n",
      "         [ 1,  2,  3],\n",
      "         [ 1,  2,  3],\n",
      "         [ 1,  2,  3],\n",
      "         [ 1,  2,  3]],\n",
      "\n",
      "        [[10, 20, 30],\n",
      "         [10, 20, 30],\n",
      "         [10, 20, 30],\n",
      "         [10, 20, 30],\n",
      "         [10, 20, 30]]]) tensor([[ 1,  2,  3],\n",
      "        [10, 20, 30]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3], [10,20,30]]) \n",
    "print(x.repeat(1, 5).shape, x.shape,'\\n>>\\n', x.repeat(1, 5), '\\n', x.repeat(1, 5).view([-1, 5, 3]), x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2D7783s2tg2"
   },
   "source": [
    "For meta-learning, we're using the excellent \"Torchmeta\" library. We have to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eX_d5hsYZtSq",
    "outputId": "4122e3c1-31d0-4e35-e770-fd46c4a5c8e4"
   },
   "outputs": [],
   "source": [
    "# !pip install torchmeta\n",
    "from torchmeta.modules import (MetaModule, MetaSequential, MetaLinear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Je35HXUPZobV"
   },
   "source": [
    "We're now ready to implement a few neural network layers: Fully connected networks, and SIREN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DlEcUhGiZobX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BatchLinear(nn.Linear, MetaModule):\n",
    "    '''A linear meta-layer that can deal with batched weight matrices and biases, as for instance output by a\n",
    "    hypernetwork.'''\n",
    "    __doc__ = nn.Linear.__doc__\n",
    "\n",
    "    def forward(self, input, params=None):\n",
    "        if params is None:\n",
    "            params = OrderedDict(self.named_parameters())\n",
    "\n",
    "        bias = params.get('bias', None)\n",
    "        weight = params['weight']\n",
    "\n",
    "        output = input.matmul(weight.permute(*[i for i in range(len(weight.shape)-2)], -1, -2))\n",
    "        output += bias.unsqueeze(-2)\n",
    "        return output\n",
    "\n",
    "\n",
    "class MetaFC(MetaModule):\n",
    "    '''A fully connected neural network that allows swapping out the weights, either via a hypernetwork\n",
    "    or via MAML.\n",
    "    '''\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 num_hidden_layers, hidden_features,\n",
    "                 outermost_linear=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(MetaSequential(\n",
    "            BatchLinear(in_features, hidden_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ))\n",
    "\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.net.append(MetaSequential(\n",
    "                BatchLinear(hidden_features, hidden_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "\n",
    "        if outermost_linear:\n",
    "            self.net.append(MetaSequential(\n",
    "                BatchLinear(hidden_features, out_features),\n",
    "            ))\n",
    "        else:\n",
    "            self.net.append(MetaSequential(\n",
    "                BatchLinear(hidden_features, out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "\n",
    "        self.net = MetaSequential(*self.net)\n",
    "        self.net.apply(init_weights_normal)\n",
    "\n",
    "    def forward(self, coords, params=None, **kwargs):\n",
    "        '''Simple forward pass without computation of spatial gradients.'''\n",
    "        output = self.net(coords, params=self.get_subdict(params, 'net'))\n",
    "        return output\n",
    "\n",
    "\n",
    "class SineLayer(MetaModule):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "\n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the\n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a\n",
    "    # hyperparameter.\n",
    "\n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of\n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = float(omega_0)\n",
    "\n",
    "        self.is_first = is_first\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.linear = BatchLinear(in_features, out_features, bias=bias)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features,\n",
    "                                            1 / self.in_features)\n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
    "                                            np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "\n",
    "    def forward(self, input, params=None):\n",
    "        intermed = self.linear(input, params=self.get_subdict(params, 'linear'))\n",
    "        return torch.sin(self.omega_0 * intermed)\n",
    "\n",
    "\n",
    "class Siren(MetaModule):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False,\n",
    "                 first_omega_0=30, hidden_omega_0=30., special_first=True):\n",
    "        super().__init__()\n",
    "        self.hidden_omega_0 = hidden_omega_0\n",
    "\n",
    "        layer = SineLayer\n",
    "\n",
    "        self.net = []\n",
    "        self.net.append(layer(in_features, hidden_features,\n",
    "                              is_first=special_first, omega_0=first_omega_0))\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.net.append(layer(hidden_features, hidden_features,\n",
    "                                  is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        if outermost_linear:\n",
    "            final_linear = BatchLinear(hidden_features, out_features)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / 30.,\n",
    "                                             np.sqrt(6 / hidden_features) / 30.)\n",
    "            self.net.append(final_linear)\n",
    "        else:\n",
    "            self.net.append(layer(hidden_features, out_features, is_first=False, omega_0=hidden_omega_0))\n",
    "\n",
    "        self.net = nn.ModuleList(self.net)\n",
    "\n",
    "    def forward(self, coords, params=None):\n",
    "        x = coords\n",
    "\n",
    "        for i, layer in enumerate(self.net):\n",
    "            x = layer(x, params=self.get_subdict(params, f'net.{i}'))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def init_weights_normal(m):\n",
    "    if type(m) == BatchLinear or nn.Linear:\n",
    "        if hasattr(m, 'weight'):\n",
    "            torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if hasattr(m, 'bias'):\n",
    "            m.bias.data.fill_(0.)\n",
    "            \n",
    "            \n",
    "def get_mgrid(sidelen):\n",
    "    # Generate 2D pixel coordinates from an image of sidelen x sidelen\n",
    "    pixel_coords = np.stack(np.mgrid[:sidelen,:sidelen], axis=-1)[None,...].astype(np.float32)\n",
    "    pixel_coords /= sidelen    \n",
    "    pixel_coords -= 0.5\n",
    "    pixel_coords = torch.Tensor(pixel_coords).view(-1, 2)\n",
    "    return pixel_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRN7_GF4jwyT"
   },
   "source": [
    "Sazan: Now let's implement our Cross-Attention Hypernetwork. It will take the image as input and generate some matrices with the same dimension as the weights of the SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i0ai6Ry7jvmE"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from modules_custom import Conv2dResBlock\n",
    "\n",
    "class CrossAttentionHyperNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        L = 256\n",
    "        self.L = L\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, padding=5//2) # padding=kernel_size//2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=5//2) # padding=kernel_size//2\n",
    "        self.conv3 = nn.Conv2d(64, L, 5, padding=5//2)\n",
    "        self.conv4 = nn.Conv2d(L, L, 5, padding=5//2)\n",
    "        # self.conv4_dim_reduction = nn.Conv2d(16+32+64, 64, 1, padding=0)\n",
    "#         self.cnn = nn.Sequential(\n",
    "#             nn.Conv2d(128, 256, 3, 1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             Conv2dResBlock(256, 256),\n",
    "#             Conv2dResBlock(256, 256),\n",
    "#             Conv2dResBlock(256, 256),\n",
    "#             Conv2dResBlock(256, 256),\n",
    "#             nn.Conv2d(256, 256, 1, 1, 0)\n",
    "#         )\n",
    "#         self.relu_2 = nn.ReLU(inplace=True)\n",
    "#         self.fc = nn.Linear(1024, 1)\n",
    "\n",
    "        if True:\n",
    "            self.fc0 = nn.Linear(L, 2)\n",
    "            self.fc1 = nn.Linear(L, L)\n",
    "            self.fc2 = nn.Linear(L, L)\n",
    "            self.fc3 = nn.Linear(L, L)\n",
    "            self.fc4_1 = nn.Linear(64, 3)\n",
    "            self.fc4_2 = nn.Linear(3, 3)\n",
    "            self.fc4_bias = nn.Linear(L, 3)\n",
    "\n",
    "        if False:\n",
    "            self.weighted_mean = torch.nn.Conv1d(in_channels=64, out_channels=5, kernel_size=1)\n",
    "\n",
    "            self.bias0_fc = nn.Linear(64+64, 64)\n",
    "            self.bias1_fc = nn.Linear(64+64, 64)\n",
    "            self.bias2_fc = nn.Linear(64+64, 64)\n",
    "            self.bias3_fc = nn.Linear(64+64, 64)\n",
    "            self.bias4_fc = nn.Linear(3+64, 3)\n",
    "            \n",
    "            self.attn_bias0_fc = nn.Linear(64, 1)\n",
    "            self.attn_bias1_fc = nn.Linear(64, 1)\n",
    "            self.attn_bias2_fc = nn.Linear(64, 1)\n",
    "            self.attn_bias3_fc = nn.Linear(64, 1)\n",
    "            self.attn_bias4_fc = nn.Linear(3, 1)\n",
    "\n",
    "\n",
    "        self.wt_cross_attn0 = nn.MultiheadAttention(embed_dim=2, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.wt_cross_attn1 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.wt_cross_attn2 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.wt_cross_attn3 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.wt_cross_attn4 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        \n",
    "        self.bias_cross_attn0 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.bias_cross_attn1 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.bias_cross_attn2 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.bias_cross_attn3 = nn.MultiheadAttention(embed_dim=self.L, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        self.bias_cross_attn4 = nn.MultiheadAttention(embed_dim=3, num_heads=1, dropout=0.1, bias=True)#, batch_first=True)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    net.0.linear.weight :\t torch.Size([64, 2]) \t torch.Size([16, 64, 2])\n",
    "    net.0.linear.bias :\t torch.Size([64]) \t torch.Size([16, 64])\n",
    "    net.1.linear.weight :\t torch.Size([64, 64]) \t torch.Size([16, 64, 64])\n",
    "    net.1.linear.bias :\t torch.Size([64]) \t torch.Size([16, 64])\n",
    "    net.2.linear.weight :\t torch.Size([64, 64]) \t torch.Size([16, 64, 64])\n",
    "    net.2.linear.bias :\t torch.Size([64]) \t torch.Size([16, 64])\n",
    "    net.3.linear.weight :\t torch.Size([64, 64]) \t torch.Size([16, 64, 64])\n",
    "    net.3.linear.bias :\t torch.Size([64]) \t torch.Size([16, 64])\n",
    "    net.4.weight :\t torch.Size([3, 64]) \t torch.Size([16, 3, 64])\n",
    "    net.4.bias :\t torch.Size([3]) \t torch.Size([16, 3])\n",
    "    '''\n",
    "    \n",
    "    def forward_conv(self, x):\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        b = x.shape[0]\n",
    "        # print('1>', x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x))) # bx3x32x32 -> bx32x16x16\n",
    "        # print('2>', x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # bx32x16x16 -> bx64x8x8 -> bx8x8x64\n",
    "        x = F.relu(self.conv3(x)) # bx32x16x16 -> bx64x8x8 -> bx8x8x64\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.permute(0, 2, 3, 1).contiguous() # bx32x16x16 -> bx64x8x8 -> bx8x8x64\n",
    "        # print('3>', x.shape)\n",
    "        # x3 = self.pool(F.relu(self.conv3(x2)))\n",
    "        # x = torch.cat([x1, x2], -1)\n",
    "        # x = F.relu(self.conv4_dim_reduction(x))\n",
    "#         print('>>', x.shape)\n",
    "        x = x.view([b, 64, self.L]) # bx8x8x64 -> bx64x64 ## channel last\n",
    "        # print('4>', x.shape)\n",
    "        \n",
    "        x0 = F.relu(self.fc0(x)) # bx64x64 -> bx64x2\n",
    "        x1 = F.relu(self.fc1(x)) # bx64x64 -> bx64x64\n",
    "        x2 = F.relu(self.fc2(x)) # bx64x64 -> bx64x64\n",
    "        x3 = F.relu(self.fc3(x)) # bx64x64 -> bx64x64\n",
    "#         print('..>>', x3.shape, x.permute(0,2,1).shape)\n",
    "        x4 = F.relu(self.fc4_1(x.permute(0,2,1))) # bx64x64 -> bx64x64 -> bx64x3\n",
    "        x4 = F.relu(self.fc4_2(x4)).permute(0,2,1).contiguous() # bx64x3 -> bx64x3 -> bx3x64\n",
    "\n",
    "        # x_biases = F.relu(self.weighted_mean(x)) # bx64x64 -> bx5x64\n",
    "        # x0_bias = F.relu(self.bias0_fc(x_biases[:, 0, :])) # bx5x64 ->  bx64 -> bx64\n",
    "        # x1_bias = F.relu(self.bias1_fc(x_biases[:, 1, :])) # bx5x64 ->  bx64 -> bx64\n",
    "        # x2_bias = F.relu(self.bias2_fc(x_biases[:, 2, :])) # bx5x64 ->  bx64 -> bx64\n",
    "        # x3_bias = F.relu(self.bias3_fc(x_biases[:, 3, :])) # bx5x64 ->  bx64 -> bx64\n",
    "        # x4_bias = F.relu(self.bias4_fc(x_biases[:, 4, :])) # bx5x64 ->  bx64 -> bx3\n",
    "\n",
    "        return x, x0, x1, x2, x3, x4#, x0_bias, x1_bias, x2_bias, x3_bias, x4_bias\n",
    "    \n",
    "    def bias_attention(self, x, meta_param_bias, bias_fc, attn_bias_fc):\n",
    "        b, c = meta_param_bias.shape\n",
    "        meta_param_bias = meta_param_bias.view(b, 1, c)\n",
    "        param_bias = torch.cat([meta_param_bias.repeat(1,64,1), x], -1) # [bx1xc, bx64x64] -> [bx64xc, bx64x64] -> bx64x(c+64)\n",
    "        param_bias = F.relu(bias_fc(param_bias)) # bx64x(c+64) -> bx64xc\n",
    "        attention_scores = F.relu(attn_bias_fc(param_bias)).permute(0,2,1) # bx64xc -> bx64x1 -> bx1x64\n",
    "        attention_scores = F.softmax(attention_scores, -1) # bx1x64 -> bx1x64\n",
    "        param_bias = torch.bmm(attention_scores, param_bias).view(b, c) # [bx1x64, bx64xc] -> bx1xc -> bxc\n",
    "        return param_bias\n",
    "\n",
    "    def compute_biases(self, x, meta_params):\n",
    "        x0_bias = self.bias_attention(x=x, meta_param_bias=meta_params['net.0.linear.bias'], bias_fc=self.bias0_fc, attn_bias_fc=self.attn_bias0_fc)\n",
    "        x1_bias = self.bias_attention(x=x, meta_param_bias=meta_params['net.1.linear.bias'], bias_fc=self.bias1_fc, attn_bias_fc=self.attn_bias1_fc)\n",
    "        x2_bias = self.bias_attention(x=x, meta_param_bias=meta_params['net.2.linear.bias'], bias_fc=self.bias2_fc, attn_bias_fc=self.attn_bias2_fc)\n",
    "        x3_bias = self.bias_attention(x=x, meta_param_bias=meta_params['net.3.linear.bias'], bias_fc=self.bias3_fc, attn_bias_fc=self.attn_bias3_fc)\n",
    "        x4_bias = self.bias_attention(x=x, meta_param_bias=meta_params['net.4.bias'], bias_fc=self.bias4_fc, attn_bias_fc=self.attn_bias4_fc)\n",
    "        return x0_bias, x1_bias, x2_bias, x3_bias, x4_bias \n",
    "\n",
    "    def compute_loss(self, specialized_param, gt_specialized_param):\n",
    "        loss = 0.\n",
    "        for key in specialized_param:\n",
    "            loss += F.mse_loss(input=specialized_param[key], target=gt_specialized_param[key])\n",
    "        loss /= 10 # not sure if it will help\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, meta_params):\n",
    "        x, x0, x1, x2, x3, x4 = self.forward_conv(x) \n",
    "        # x0_bias, x1_bias, x2_bias, x3_bias, x4_bias = self.compute_biases(x, meta_params)\n",
    "\n",
    "        # x = self.forward_conv(x) # bx32x32x3 -> bx64x64\n",
    "        b, l, c = x.shape\n",
    "        # query -> from meta model ==> meta_params\n",
    "        # key and value -> from this model ==> x\n",
    "        specialized_param = OrderedDict()\n",
    "\n",
    "        # print('1>', meta_params['net.4.bias'].shape, x.shape)\n",
    "        # x_in = self.fc0(x)\n",
    "        x_out = F.relu(self.fc4_bias(x))\n",
    "        specialized_param['net.0.linear.weight']  = self.wt_cross_attn0(query=meta_params['net.0.linear.weight'], key=x0, value=x0)[0]\n",
    "        specialized_param['net.0.linear.bias']  = self.bias_cross_attn0(query=meta_params['net.0.linear.bias'].view(b, 1, -1), key=x, value=x)[0].view(b, -1)\n",
    "        specialized_param['net.1.linear.weight']  = self.wt_cross_attn1(query=meta_params['net.1.linear.weight'], key=x1, value=x1)[0]\n",
    "        specialized_param['net.1.linear.bias']  = self.bias_cross_attn1(query=meta_params['net.1.linear.bias'].view(b, 1, -1), key=x, value=x)[0].view(b, -1)\n",
    "        specialized_param['net.2.linear.weight']  = self.wt_cross_attn2(query=meta_params['net.2.linear.weight'], key=x2, value=x2)[0]\n",
    "        specialized_param['net.2.linear.bias']  = self.bias_cross_attn2(query=meta_params['net.2.linear.bias'].view(b, 1, -1), key=x, value=x)[0].view(b, -1)\n",
    "        specialized_param['net.3.linear.weight']  = self.wt_cross_attn3(query=meta_params['net.3.linear.weight'], key=x3, value=x3)[0]\n",
    "        specialized_param['net.3.linear.bias']  = self.bias_cross_attn3(query=meta_params['net.3.linear.bias'].view(b, 1, -1), key=x, value=x)[0].view(b, -1)\n",
    "        specialized_param['net.4.weight']  = self.wt_cross_attn4(query=meta_params['net.4.weight'], key=x4, value=x4)[0]\n",
    "        specialized_param['net.4.bias']  = self.bias_cross_attn4(query=meta_params['net.4.bias'].view(b, 1, -1), key=x_out, value=x_out)[0].view(b, -1)\n",
    "\n",
    "#         loss = self.compute_loss(specialized_param, gt_specialized_param)\n",
    "\n",
    "#         return loss, specialized_param\n",
    "        return specialized_param\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhPvd2TUkZC8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cPO4PWDZobZ"
   },
   "source": [
    "Now, we implement MAML. The important parts of the code are commented, so it's easy to understand how each part works! Start by looking at the \"forward\" function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OL4dgzRiZoba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def l2_loss(prediction, gt):\n",
    "    return ((prediction - gt)**2).mean()\n",
    "\n",
    "\n",
    "class MAML(nn.Module):\n",
    "    def __init__(self, num_meta_steps, hypo_module, crossAttHypNet, loss, init_lr,\n",
    "                 lr_type='static', first_order=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hypo_module = hypo_module # The module who's weights we want to meta-learn.\n",
    "        self.crossAttHypNet = crossAttHypNet\n",
    "        self.first_order = first_order\n",
    "        self.loss = loss\n",
    "        self.lr_type = lr_type\n",
    "        self.log = []\n",
    "\n",
    "        self.register_buffer('num_meta_steps', torch.Tensor([num_meta_steps]).int())\n",
    "\n",
    "        if self.lr_type == 'static': \n",
    "            self.register_buffer('lr', torch.Tensor([init_lr]))\n",
    "        elif self.lr_type == 'global':\n",
    "            self.lr = nn.Parameter(torch.Tensor([init_lr]))\n",
    "        elif self.lr_type == 'per_step':\n",
    "            self.lr = nn.ParameterList([nn.Parameter(torch.Tensor([init_lr]))\n",
    "                                        for _ in range(num_meta_steps)])\n",
    "        elif self.lr_type == 'per_parameter': # As proposed in \"Meta-SGD\".\n",
    "            self.lr = nn.ParameterList([])\n",
    "            hypo_parameters = hypo_module.parameters()\n",
    "            for param in hypo_parameters:\n",
    "                self.lr.append(nn.Parameter(torch.ones(param.size()) * init_lr))\n",
    "        elif self.lr_type == 'per_parameter_per_step':\n",
    "            self.lr = nn.ModuleList([])\n",
    "            for name, param in hypo_module.meta_named_parameters():\n",
    "                self.lr.append(nn.ParameterList([nn.Parameter(torch.ones(param.size()) * init_lr)\n",
    "                                                 for _ in range(num_meta_steps)]))\n",
    "\n",
    "        param_count = 0\n",
    "        for param in self.parameters():\n",
    "            param_count += np.prod(param.shape)\n",
    "\n",
    "        print(param_count)\n",
    "\n",
    "    def _update_step(self, loss, param_dict, step):\n",
    "        grads = torch.autograd.grad(loss, param_dict.values(),\n",
    "                                    create_graph=False if self.first_order else True)\n",
    "        params = OrderedDict()\n",
    "        for i, ((name, param), grad) in enumerate(zip(param_dict.items(), grads)):\n",
    "            if self.lr_type in ['static', 'global']:\n",
    "                lr = self.lr\n",
    "                params[name] = param - lr * grad\n",
    "            elif self.lr_type in ['per_step']:\n",
    "                lr = self.lr[step]\n",
    "                params[name] = param - lr * grad\n",
    "            elif self.lr_type in ['per_parameter']:\n",
    "                lr = self.lr[i]\n",
    "                params[name] = param - lr * grad\n",
    "            elif self.lr_type in ['per_parameter_per_step']:\n",
    "                lr = self.lr[i][step]\n",
    "                params[name] = param - lr * grad\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        return params, grads\n",
    "\n",
    "    def forward_with_params(self, query_x, fast_params, **kwargs):\n",
    "        output = self.hypo_module(query_x, params=fast_params)\n",
    "        return output\n",
    "\n",
    "    def generate_params(self, context_dict):\n",
    "        \"\"\"Specializes the model\"\"\"\n",
    "        x = context_dict.get('x').cuda()\n",
    "        y = context_dict.get('y').cuda()\n",
    "\n",
    "        meta_batch_size = x.shape[0]\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            # First, replicate the initialization for each batch item.\n",
    "            # This is the learned initialization, i.e., in the outer loop,\n",
    "            # the gradients are backpropagated all the way into the \n",
    "            # \"meta_named_parameters\" of the hypo_module.\n",
    "            fast_params = OrderedDict()\n",
    "            meta_params = OrderedDict()\n",
    "            for name, param in self.hypo_module.meta_named_parameters():\n",
    "                fast_params[name] = param[None, ...].repeat((meta_batch_size,) + (1,) * len(param.shape))\n",
    "                meta_params[name] = param[None, ...].repeat((meta_batch_size,) + (1,) * len(param.shape))\n",
    "\n",
    "            prev_loss = 1e6\n",
    "            intermed_predictions = []\n",
    "            for j in range(self.num_meta_steps):\n",
    "                # Using the current set of parameters, perform a forward pass with the context inputs.\n",
    "                predictions = self.hypo_module(x, params=fast_params)\n",
    "\n",
    "                # Compute the loss on the context labels.\n",
    "                loss = self.loss(predictions, y)\n",
    "                intermed_predictions.append(predictions)\n",
    "\n",
    "                if loss > prev_loss:\n",
    "                    print('inner lr too high?')\n",
    "                \n",
    "                # Using the computed loss, update the fast parameters.\n",
    "                fast_params, grads = self._update_step(loss, fast_params, j)\n",
    "                prev_loss = loss\n",
    "\n",
    "        return fast_params, intermed_predictions, meta_params\n",
    "\n",
    "    def forward(self, meta_batch, **kwargs):\n",
    "        # The meta_batch conists of the \"context\" set (the observations we're conditioning on)\n",
    "        # and the \"query\" inputs (the points where we want to evaluate the specialized model)\n",
    "        context = meta_batch['context']\n",
    "        query_x = meta_batch['query']['x'].cuda()\n",
    "\n",
    "        # Specialize the model with the \"generate_params\" function.\n",
    "        fast_params, intermed_predictions, meta_params = self.generate_params(context)\n",
    "        pred_specialized_param = self.crossAttHypNet(x=lin2img(context['y']).cuda(), meta_params=meta_params)#, gt_specialized_param=fast_params)\n",
    "\n",
    "        pred_specialized_param_corrected = OrderedDict()\n",
    "\n",
    "        crossAttHypNet_loss = 0.\n",
    "        if True:\n",
    "            l1, l2 = pred_specialized_param.keys(), fast_params.keys()\n",
    "            for (name1, name2) in list(zip(l1, l2)):\n",
    "                pred_specialized_param_corrected[name2] = meta_params[name2] + pred_specialized_param[name1]\n",
    "#                 crossAttHypNet_loss += ((pred_specialized_param_corrected[name2] - fast_params[name2].detach()) ** 2).mean()\n",
    "                \n",
    "        # Compute the final outputs. \n",
    "        model_output = self.hypo_module(query_x, params=fast_params)\n",
    "        model_output_hypernet = self.hypo_module(query_x, params=pred_specialized_param_corrected)\n",
    "        crossAttHypNet_loss += self.loss(model_output_hypernet, context['y'])\n",
    "        out_dict = {'model_out':model_output, 'intermed_predictions':intermed_predictions, \n",
    "                    'crossAttHypNet_loss':crossAttHypNet_loss, \n",
    "                    'model_output_hypernet': model_output_hypernet}\n",
    "\n",
    "        return out_dict, fast_params, meta_params, pred_specialized_param_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i0VRikaZobc"
   },
   "source": [
    "<a id='section_1'></a>\n",
    "## Learning to fit images in 3 gradient descent steps\n",
    "\n",
    "By learning an initialization for SIREN, we may fit any image in as few as 3 gradient descent steps! \n",
    "This has also been noted by Tancik et al. in \"Learned Initializations for Optimizing Coordinate-Based Neural Representations\" (2020).\n",
    "\n",
    "We'll demonstrate here with Cifar-10, but it works just as well with CelebA or imagenet - try it out yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gKFj5-FVZobc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CIFAR10():\n",
    "    def __init__(self):\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "        self.dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                                download=True, transform=transform)\n",
    "        \n",
    "        self.length = len(self.dataset)\n",
    "        self.meshgrid = get_mgrid(sidelen=32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        img, _ = self.dataset[item]\n",
    "        img_flat = img.permute(1,2,0).view(-1, 3)\n",
    "        return {'context':{'x':self.meshgrid, 'y':img_flat}, \n",
    "                'query':{'x':self.meshgrid, 'y':img_flat}}\n",
    "\n",
    "\n",
    "def lin2img(tensor):\n",
    "    batch_size, num_samples, channels = tensor.shape\n",
    "    sidelen = np.sqrt(num_samples).astype(int)\n",
    "    return tensor.view(batch_size, sidelen, sidelen, channels).squeeze(-1)\n",
    "\n",
    "    \n",
    "def plot_sample_image(img_batch, ax):\n",
    "    img = lin2img(img_batch)[0].detach().cpu().numpy()\n",
    "    img += 1\n",
    "    img /= 2.\n",
    "    img = np.clip(img, 0., 1.)\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def dict_to_gpu(ob):\n",
    "    if isinstance(ob, Mapping):\n",
    "        return {k: dict_to_gpu(v) for k, v in ob.items()}\n",
    "    else:\n",
    "        return ob.cuda()    \n",
    "\n",
    "\n",
    "# def dict_to_gpu(ob):\n",
    "#     if isinstance(ob, Mapping):\n",
    "#         return {k: dict_to_gpu(v) for k, v in ob.items()}\n",
    "#     else:\n",
    "#         return ob.cuda()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9t9tBE4EZobd"
   },
   "source": [
    "Now, let's initialize our models and our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKLBYi25Zobd",
    "outputId": "b6694221-afa4-472e-a572-198500159e14",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5202152\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import meta_modules\n",
    "img_siren = Siren(in_features=2, hidden_features=256, hidden_layers=3, out_features=3, outermost_linear=True)\n",
    "img_siren.load_state_dict(torch.load('img_siren_crossAttn0.pth'))\n",
    "crossAttHypNet = CrossAttentionHyperNet()\n",
    "# crossAttHypNet = meta_modules.ConvolutionalNeuralProcessImplicit2DHypernet(in_features=3,\n",
    "#                                                                     out_features=3,\n",
    "#                                                                     image_resolution=(32, 32))\n",
    "crossAttHypNet.load_state_dict(torch.load('crossAttHypNet_crossAttn0.pth'))\n",
    "meta_siren = MAML(num_meta_steps=3, hypo_module=img_siren.cuda(), crossAttHypNet=crossAttHypNet.cuda(), \n",
    "                  loss=l2_loss, init_lr=1e-5, \n",
    "                  lr_type='per_parameter_per_step').cuda()\n",
    "meta_siren.load_state_dict(torch.load('meta_siren_crossAttn0.pth'))\n",
    "meta_siren = meta_siren.cuda()\n",
    "if True:\n",
    "    del crossAttHypNet\n",
    "    torch.cuda.empty_cache()\n",
    "    crossAttHypNet = CrossAttentionHyperNet()\n",
    "    meta_siren.crossAttHypNet = crossAttHypNet.cuda()\n",
    "meta_siren.train()\n",
    "\n",
    "dataset = CIFAR10()\n",
    "dataloader = DataLoader(dataset, batch_size=16, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lJQ3Fdr-zvIB"
   },
   "outputs": [],
   "source": [
    "# crossAttHypNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5dv0PYqRZlN",
    "outputId": "8a79253e-e5de-4e2b-8c11-147675e8b438"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# img1 = cv2.imread('img1.bmp')\n",
    "# img2 = cv2.imread('img2.bmp')\n",
    "# psnr = cv2.PSNR(img1, img2)\n",
    "# psnr\n",
    "\n",
    "from metrics import psnr, ssim_metric\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WS7Juv9HZobf"
   },
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "pzmwE0_KZobg",
    "outputId": "96cc34be-e0a5-41f8-f455-1c68d3579309",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 0,\tTotal loss: 0.389327,\tHypernet loss: 0.387830\n",
      "\tPSNR: nan \tSSIM: nan\n",
      "[64.38391122383804, 74.77068254771278, 82.10711904437733, 84.6293130735387, 61.084393292747606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1000,\tTotal loss: 0.202353,\tHypernet loss: 0.201189\n",
      "\tPSNR: 12.336253091931344 \tSSIM: 0.3040946621182375\n",
      "[59.62914403580626, 74.62645387889201, 81.34494524436774, 84.97643463897559, 61.7036996473881]\n",
      "Epoch 0, Step 2000,\tTotal loss: 0.355600,\tHypernet loss: 0.354353\n",
      "\tPSNR: 12.442884672954678 \tSSIM: 0.31975907939460013\n",
      "[55.518377420450705, 72.31014904866095, 76.19424929377166, 80.2361783573063, 61.71964317911418]\n",
      "Epoch 0, Step 3000,\tTotal loss: 0.232362,\tHypernet loss: 0.231557\n",
      "\tPSNR: 12.506600137770176 \tSSIM: 0.3275021126588496\n",
      "[57.80728210827921, 77.4616647793954, 82.40583187743064, 86.52702687338055, 58.75694346718471]\n",
      "Epoch 1, Step 0,\tTotal loss: 0.270515,\tHypernet loss: 0.269841\n",
      "\tPSNR: 12.51094042886734 \tSSIM: 0.3282304415172711\n",
      "[53.16645484947823, 78.18450501942151, 83.86264969110128, 88.18309963505733, 60.13129155082674]\n",
      "Epoch 1, Step 1000,\tTotal loss: 0.239780,\tHypernet loss: 0.238773\n",
      "\tPSNR: 12.541579639499838 \tSSIM: 0.33227261033926553\n",
      "[59.100387099507444, 76.16127310314342, 81.87346217662164, 88.88842205404919, 54.7555379577138]\n",
      "Epoch 1, Step 2000,\tTotal loss: 0.272412,\tHypernet loss: 0.271539\n",
      "\tPSNR: 12.570334614695572 \tSSIM: 0.33456991949744475\n",
      "[51.52775048698644, 78.06046222775575, 83.55579374822918, 88.51135986310952, 58.34065062290475]\n",
      "Epoch 1, Step 3000,\tTotal loss: 0.218969,\tHypernet loss: 0.218055\n",
      "\tPSNR: 12.59228576949178 \tSSIM: 0.3362699066769161\n",
      "[59.042292770613535, 79.34571808078793, 85.07950911487288, 90.5200830771556, 61.27230713546504]\n",
      "Epoch 2, Step 0,\tTotal loss: 0.204998,\tHypernet loss: 0.204447\n",
      "\tPSNR: 12.595438562231063 \tSSIM: 0.33641936875290235\n",
      "[55.93643389769389, 76.9976755420662, 81.93024635914641, 86.03557145065112, 64.06931584268838]\n",
      "Epoch 2, Step 1000,\tTotal loss: 0.270390,\tHypernet loss: 0.269473\n",
      "\tPSNR: 12.61542546520973 \tSSIM: 0.33791886775462954\n",
      "[54.59875971969063, 77.57043979644078, 83.66327570701176, 88.68791514237597, 60.40257671265912]\n",
      "Epoch 2, Step 2000,\tTotal loss: 0.212678,\tHypernet loss: 0.211851\n",
      "\tPSNR: 12.632699857086847 \tSSIM: 0.3390887609186836\n",
      "[52.484634717658956, 77.80477475498347, 82.92898540125103, 86.49251434211209, 62.157460075900765]\n",
      "Epoch 2, Step 3000,\tTotal loss: 0.243865,\tHypernet loss: 0.242755\n",
      "\tPSNR: 12.646867500756239 \tSSIM: 0.3402984407629214\n",
      "[54.45605007721558, 76.1802884392962, 81.91380036648349, 86.68679522234169, 60.58794466154379]\n",
      "Epoch 3, Step 0,\tTotal loss: 0.280737,\tHypernet loss: 0.280092\n",
      "\tPSNR: 12.64870423157374 \tSSIM: 0.3404789002978802\n",
      "[55.09426081790521, 78.75094390519551, 84.05479905500839, 87.84965594767444, 64.19023608144443]\n",
      "Epoch 3, Step 1000,\tTotal loss: 0.188815,\tHypernet loss: 0.188136\n",
      "\tPSNR: 12.66209049324817 \tSSIM: 0.34159366567689553\n",
      "[53.612097460206094, 76.9292758673595, 82.34351364795474, 87.56460870375179, 60.47528976095764]\n",
      "Epoch 3, Step 2000,\tTotal loss: 0.219830,\tHypernet loss: 0.219286\n",
      "\tPSNR: 12.67387668980085 \tSSIM: 0.34261022731764906\n",
      "[53.82732837266826, 76.98766963524969, 82.93702986297966, 88.57551426175894, 61.63417844422638]\n",
      "Epoch 3, Step 3000,\tTotal loss: 0.204077,\tHypernet loss: 0.203445\n",
      "\tPSNR: 12.683525465649788 \tSSIM: 0.3434700532733684\n",
      "[55.257070461273116, 73.50411442426193, 79.56650308271658, 85.93470794298675, 57.54968316432808]\n",
      "Epoch 4, Step 0,\tTotal loss: 0.206510,\tHypernet loss: 0.205985\n",
      "\tPSNR: 12.684112782046794 \tSSIM: 0.3435938090816629\n",
      "[55.31029646598479, 77.02270284497031, 82.43755892716561, 87.19381132467994, 63.02304896718739]\n",
      "Epoch 4, Step 1000,\tTotal loss: 0.231198,\tHypernet loss: 0.230614\n",
      "\tPSNR: 12.692649936658364 \tSSIM: 0.34441355560887155\n",
      "[54.98468851921168, 76.53904870118298, 81.80160504363117, 86.57063664935819, 61.8971171023301]\n",
      "Epoch 4, Step 2000,\tTotal loss: 0.264603,\tHypernet loss: 0.264199\n",
      "\tPSNR: 12.699725668228906 \tSSIM: 0.3451371274629893\n",
      "[55.438234227030236, 78.309627604273, 84.56297621460175, 89.35568048377309, 63.482724951615346]\n",
      "Epoch 4, Step 3000,\tTotal loss: 0.210792,\tHypernet loss: 0.209255\n",
      "\tPSNR: 12.706734420734067 \tSSIM: 0.3458161345117635\n",
      "[56.6626667861408, 73.05987353736712, 77.24678710926128, 81.21479355942725, 59.44165748148518]\n",
      "Epoch 5, Step 0,\tTotal loss: 0.282608,\tHypernet loss: 0.282021\n",
      "\tPSNR: 12.70840770737648 \tSSIM: 0.34592630763242393\n",
      "[50.928158531650666, 75.15225063175849, 80.0956846510995, 84.14278602958316, 57.83033167130569]\n",
      "Epoch 5, Step 1000,\tTotal loss: 0.289172,\tHypernet loss: 0.288500\n",
      "\tPSNR: 12.713562548269904 \tSSIM: 0.34654290220556655\n",
      "[53.71577176028043, 78.3513358803733, 84.752647815606, 90.11256240331996, 63.859295822108926]\n",
      "Epoch 5, Step 2000,\tTotal loss: 0.243541,\tHypernet loss: 0.243094\n",
      "\tPSNR: 12.720128563845412 \tSSIM: 0.34709861801783076\n",
      "[57.712105571220114, 80.61534588726116, 88.25822049843765, 93.94897800622174, 62.48099771004342]\n",
      "Epoch 5, Step 3000,\tTotal loss: 0.227008,\tHypernet loss: 0.226446\n",
      "\tPSNR: 12.7256414770936 \tSSIM: 0.34766045270532436\n",
      "[54.38329480136077, 72.83224347220138, 78.78953134473446, 84.45994138276367, 56.94097753148871]\n",
      "Epoch 6, Step 0,\tTotal loss: 0.296254,\tHypernet loss: 0.295736\n",
      "\tPSNR: 12.726514518984159 \tSSIM: 0.3477405609904703\n",
      "[57.970530233608734, 79.36206260195334, 85.98094454903034, 91.62043969760785, 60.79439020755609]\n",
      "Epoch 6, Step 1000,\tTotal loss: 0.289165,\tHypernet loss: 0.288608\n",
      "\tPSNR: 12.732872165922878 \tSSIM: 0.3482631899721197\n",
      "[56.87407416377213, 75.15390233662264, 81.19017954997761, 87.91032988322102, 57.59470735919291]\n",
      "Epoch 6, Step 2000,\tTotal loss: 0.196935,\tHypernet loss: 0.196180\n",
      "\tPSNR: 12.735622142995696 \tSSIM: 0.34870915718496487\n",
      "[56.429286015878645, 75.4928126461874, 79.66814742812598, 83.19027660252965, 62.45315367843894]\n",
      "Epoch 6, Step 3000,\tTotal loss: 0.224577,\tHypernet loss: 0.224232\n",
      "\tPSNR: 12.740708603545167 \tSSIM: 0.3491959924856636\n",
      "[53.82565358639422, 76.14259105858402, 82.74864916336789, 87.83963942458804, 60.22807064499553]\n",
      "Epoch 7, Step 0,\tTotal loss: 0.242008,\tHypernet loss: 0.241518\n",
      "\tPSNR: 12.740968779608863 \tSSIM: 0.34924777674809165\n",
      "[54.81065825985883, 77.75298731724189, 84.362763765594, 90.36929928453296, 64.99844361854089]\n",
      "Epoch 7, Step 1000,\tTotal loss: 0.260017,\tHypernet loss: 0.259394\n",
      "\tPSNR: 12.745267513701172 \tSSIM: 0.34968140645623474\n",
      "[52.841159407102865, 75.50746981822536, 80.9752772887215, 85.23388193645344, 59.23943120744034]\n",
      "Epoch 7, Step 2000,\tTotal loss: 0.241750,\tHypernet loss: 0.241212\n",
      "\tPSNR: 12.74854654514852 \tSSIM: 0.3500944738926723\n",
      "[53.94476780064616, 75.78889777637626, 81.76717838408209, 87.18191250208058, 61.23864751249031]\n",
      "Epoch 7, Step 3000,\tTotal loss: 0.188866,\tHypernet loss: 0.188271\n",
      "\tPSNR: 12.751931140995504 \tSSIM: 0.35049958003717696\n",
      "[54.747640340650236, 75.71113800337017, 80.3855659908715, 83.80186175808481, 61.316193882621796]\n",
      "Epoch 8, Step 0,\tTotal loss: 0.248002,\tHypernet loss: 0.247415\n",
      "\tPSNR: 12.752276727524995 \tSSIM: 0.35051509550026677\n",
      "[56.195701344668045, 78.51695646913514, 85.06407339794126, 91.6966481479304, 58.6431220156794]\n",
      "Epoch 8, Step 1000,\tTotal loss: 0.217858,\tHypernet loss: 0.217450\n",
      "\tPSNR: 12.755656697914004 \tSSIM: 0.35085560683185896\n",
      "[52.96439510310108, 77.17388524664582, 83.57936969833064, 88.97411213940144, 60.39943044961632]\n",
      "Epoch 8, Step 2000,\tTotal loss: 0.264408,\tHypernet loss: 0.263983\n",
      "\tPSNR: 12.757994742703659 \tSSIM: 0.35120040250533713\n",
      "[52.773216205143456, 76.79877564464319, 82.09247769781051, 86.22200151266753, 61.4826543177774]\n",
      "Epoch 8, Step 3000,\tTotal loss: 0.237115,\tHypernet loss: 0.236378\n",
      "\tPSNR: 12.76127696870161 \tSSIM: 0.351555428154456\n",
      "[53.32599069033725, 76.64606147898778, 83.7156206405947, 90.46478711157201, 58.45058222402947]\n",
      "Epoch 9, Step 0,\tTotal loss: 0.252947,\tHypernet loss: 0.252507\n",
      "\tPSNR: 12.761641991526286 \tSSIM: 0.35160188845792706\n",
      "[55.540671520858695, 75.42842999992926, 80.48335708253232, 83.97413986076816, 61.239883990460626]\n",
      "Epoch 9, Step 1000,\tTotal loss: 0.245460,\tHypernet loss: 0.244972\n",
      "\tPSNR: 12.764680285995098 \tSSIM: 0.3519465374514481\n",
      "[58.57781656082988, 78.07335009825508, 84.89147702369648, 91.64784152158808, 58.85642909597493]\n",
      "Epoch 9, Step 2000,\tTotal loss: 0.241743,\tHypernet loss: 0.241340\n",
      "\tPSNR: 12.767237333225511 \tSSIM: 0.35225350768602653\n",
      "[53.20322992637617, 77.13746872431501, 83.15782527836255, 88.36697289037215, 60.40939388522481]\n",
      "Epoch 9, Step 3000,\tTotal loss: 0.228091,\tHypernet loss: 0.227648\n",
      "\tPSNR: 12.76877496306676 \tSSIM: 0.35249648244175374\n",
      "[53.85250048773541, 75.50500573941508, 80.97880278273482, 85.79491953111669, 60.85805765013782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 12.768776614245414\n",
      "SSIM: 0.35252551848940017\n",
      "500000 50000\n",
      "\n",
      "epoch:0\n",
      "PSNR: 12.51094042886734\n",
      "SSIM: 0.3282304415172711\n",
      "\n",
      "epoch:1\n",
      "PSNR: 12.679936695594787\n",
      "SSIM: 0.34460829598853365\n",
      "\n",
      "epoch:2\n",
      "PSNR: 12.755235570259094\n",
      "SSIM: 0.3485979633878358\n",
      "\n",
      "epoch:3\n",
      "PSNR: 12.790338433465958\n",
      "SSIM: 0.3529385354330111\n",
      "\n",
      "epoch:4\n",
      "PSNR: 12.80558740869522\n",
      "SSIM: 0.355256301835468\n",
      "\n",
      "epoch:5\n",
      "PSNR: 12.817048577022552\n",
      "SSIM: 0.35681182778070214\n",
      "\n",
      "epoch:6\n",
      "PSNR: 12.827694343357086\n",
      "SSIM: 0.3582910712938197\n",
      "\n",
      "epoch:7\n",
      "PSNR: 12.831432362937928\n",
      "SSIM: 0.35938632676549254\n",
      "\n",
      "epoch:8\n",
      "PSNR: 12.836564103536606\n",
      "SSIM: 0.3602962321192096\n",
      "\n",
      "epoch:9\n",
      "PSNR: 12.832988218717576\n",
      "SSIM: 0.3608381887726579\n"
     ]
    }
   ],
   "source": [
    "steps_til_summary = 1000\n",
    "\n",
    "# optim = torch.optim.Adam(lr=5e-5, params=meta_siren.parameters())\n",
    "optim = torch.optim.Adam(lr=5e-6, params=meta_siren.parameters())\n",
    "\n",
    "hypernet_loss_multiplier = 1\n",
    "\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "for epoch in range(10):\n",
    "#     if epoch < 10:\n",
    "#         hypernet_loss_multiplier += 100\n",
    "\n",
    "    for step, sample in enumerate(dataloader):\n",
    "        sample = dict_to_gpu(sample)\n",
    "        '''\n",
    "        out_dict = {'model_out':model_output, 'intermed_predictions':intermed_predictions, \n",
    "                    'crossAttHypNet_loss':crossAttHypNet_loss, \n",
    "                    'model_output_hypernet': model_output_hypernet}\n",
    "\n",
    "        return out_dict, fast_params, meta_params, pred_specialized_param\n",
    "        '''\n",
    "        model_output, fast_params, meta_params, pred_specialized_param = meta_siren(sample)    \n",
    "        loss = ((model_output['model_out'] - sample['query']['y'])**2).mean() + hypernet_loss_multiplier * model_output['crossAttHypNet_loss']\n",
    "        \n",
    "#         for name in pred_specialized_param:\n",
    "#             loss += 10*((pred_specialized_param[name] - fast_params[name].detach()) ** 2).mean()\n",
    "        if False:\n",
    "            pred_specialized_param_corrected = OrderedDict()\n",
    "            l1, l2 = pred_specialized_param.keys(), fast_params.keys()\n",
    "            for (name1, name2) in list(zip(l1, l2)):\n",
    "                pred_specialized_param_corrected[name2] = meta_params[name2] + pred_specialized_param[name1]\n",
    "#                 pred_specialized_param_corrected[name2] = pred_specialized_param[name1]\n",
    "                loss += 1*((pred_specialized_param_corrected[name2] - fast_params[name2].detach()) ** 2).mean()\n",
    "       \n",
    "        \n",
    "        if (step % steps_til_summary == 0) and (epoch % 1 == 0): \n",
    "            print(\"Epoch %d, Step %d,\\tTotal loss: %0.6f,\\tHypernet loss: %0.6f\" % (epoch, step, loss, model_output['crossAttHypNet_loss']))\n",
    "            print('\\tPSNR:', np.mean(psnr_list), '\\tSSIM:', np.mean(ssim_list))\n",
    "            fig, axes = [], list(range(6))#plt.subplots(1,6, figsize=(36,6))\n",
    "            ax_titles = ['Learned Initialization', 'Inner step 1 output', \n",
    "                        'Inner step 2 output', 'Inner step 3 output', \n",
    "                        'HyperNet output', ## added by me\n",
    "                        'Ground Truth']\n",
    "            images = []\n",
    "            for i, inner_step_out in enumerate(model_output['intermed_predictions']):\n",
    "                img = plot_sample_image(inner_step_out, ax=axes[i])\n",
    "                images += [img]\n",
    "#                 axes[i].set_title(ax_titles[i], fontsize=25)\n",
    "            images += [plot_sample_image(model_output['model_out'], ax=axes[-3])]\n",
    "#             axes[-3].set_title(ax_titles[-3], fontsize=25)\n",
    "\n",
    "            if True:\n",
    "                images += [plot_sample_image(model_output['model_output_hypernet'], ax=axes[-2])]\n",
    "#                 axes[-2].set_title(ax_titles[-2], fontsize=25)\n",
    "\n",
    "            img_ground_truth = plot_sample_image(sample['query']['y'], ax=axes[-1])\n",
    "#             axes[-1].set_title(ax_titles[-1], fontsize=25)\n",
    "            psnrs = [cv2.PSNR(img_ground_truth, img) for img in images]\n",
    "            print(psnrs)\n",
    "            plt.show()\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        if True:\n",
    "            x = lin2img(model_output['model_output_hypernet']).permute(0,3,1,2).contiguous().cpu().detach()\n",
    "            x += 1.\n",
    "            x /= 2.\n",
    "            x = torch.clip(x, 0., 1.)\n",
    "            y = lin2img(sample['query']['y']).permute(0,3,1,2).contiguous().cpu().detach()\n",
    "            y += 1.\n",
    "            y /= 2.\n",
    "            y = torch.clip(y, 0., 1.)\n",
    "    #         print(x.shape, lin2img(x).shape)\n",
    "#             print(y.min(), y.max())\n",
    "#             print(x.min(), x.max())\n",
    "\n",
    "#             print('PSNR:', psnr(y, x).mean())\n",
    "#             print('psnr_sklearn:', psnr_sklearn(y.numpy(), x.numpy(), data_range=1.))\n",
    "#             print('SSIM:', ssim_metric(y, x))\n",
    "            psnr_list += psnr(y, x).cpu().detach().numpy().tolist()\n",
    "            ssim_list += ssim_metric(y, x).cpu().detach().numpy().tolist()\n",
    "        del model_output, fast_params, meta_params, pred_specialized_param\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() \n",
    "        \n",
    "print('PSNR:', np.mean(psnr_list))\n",
    "print('SSIM:', np.mean(ssim_list))\n",
    "\n",
    "l = len(psnr_list) // 10\n",
    "print(len(psnr_list), l)\n",
    "for i in range(10):\n",
    "    print(f'\\nepoch:{i}\\nPSNR:', np.mean(psnr_list[l*i:l*(i+1)]))\n",
    "    print('SSIM:', np.mean(ssim_list[l*i:l*(i+1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "l4Ca0dY2xr2w"
   },
   "outputs": [],
   "source": [
    "# ## fast_params['net.0.linear.weight'].requires_grad\n",
    "# # fast_params.keys()\n",
    "# # fast_params['net.1.linear.weight'].shape \n",
    "# # for key in fast_params:\n",
    "# #     print(fast_params[key].shape)\n",
    "# for key in meta_params:\n",
    "#     print(key, ':\\t', meta_params[key].shape, '\\t', fast_params[key].shape)\n",
    "\n",
    "\n",
    "torch.save(img_siren.state_dict(), 'img_siren_crossAttn0.pth')\n",
    "torch.save(crossAttHypNet.state_dict(), 'crossAttHypNet_crossAttn0.pth')\n",
    "torch.save(meta_siren.state_dict(), 'meta_siren_crossAttn0.pth')\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "import json\n",
    "json.dump({'psnr_list': psnr_list, 'ssim_list': ssim_list}, open('psnr_ssim_list_hypernet+crossAttn.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iT1Qy7983EbD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000 50000\n",
      "\n",
      "epoch:0\n",
      "PSNR: 12.51094042886734\n",
      "SSIM: 0.3282304415172711\n",
      "\n",
      "epoch:1\n",
      "PSNR: 12.679936695594787\n",
      "SSIM: 0.34460829598853365\n",
      "\n",
      "epoch:2\n",
      "PSNR: 12.755235570259094\n",
      "SSIM: 0.3485979633878358\n",
      "\n",
      "epoch:3\n",
      "PSNR: 12.790338433465958\n",
      "SSIM: 0.3529385354330111\n",
      "\n",
      "epoch:4\n",
      "PSNR: 12.80558740869522\n",
      "SSIM: 0.355256301835468\n",
      "\n",
      "epoch:5\n",
      "PSNR: 12.817048577022552\n",
      "SSIM: 0.35681182778070214\n",
      "\n",
      "epoch:6\n",
      "PSNR: 12.827694343357086\n",
      "SSIM: 0.3582910712938197\n",
      "\n",
      "epoch:7\n",
      "PSNR: 12.831432362937928\n",
      "SSIM: 0.35938632676549254\n",
      "\n",
      "epoch:8\n",
      "PSNR: 12.836564103536606\n",
      "SSIM: 0.3602962321192096\n",
      "\n",
      "epoch:9\n",
      "PSNR: 12.832988218717576\n",
      "SSIM: 0.3608381887726579\n"
     ]
    }
   ],
   "source": [
    "l = len(psnr_list) // 10\n",
    "print(len(psnr_list), l)\n",
    "for i in range(10):\n",
    "    print(f'\\nepoch:{i}\\nPSNR:', np.mean(psnr_list[l*i:l*(i+1)]))\n",
    "    print('SSIM:', np.mean(ssim_list[l*i:l*(i+1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kryu4N59GVaB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MetaSDF_on_Cifar_10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
